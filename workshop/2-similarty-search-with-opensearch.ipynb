{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Using Langchain to create a custom prompt\n",
    "\n",
    "The _Retrieval_ portion or the _Retrieval Augmented Generation_ (RAG) pattern allows you to generate responses based on your data. \n",
    "\n",
    "Example:\n",
    "    You're searching for information that can be compiled from multiple documents.\n",
    "\n",
    "Instead of providing the links to all the documents alone and configuring highlighting for each piece.\n",
    "\n",
    "That being said we have vector embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from opensearchpy import OpenSearch\n",
    "\n",
    "connection_string = os.getenv(\"OPENSEARCH_SERVICE_URI\")\n",
    "\n",
    "# Create the client with SSL/TLS enabled, but hostname verification disabled.\n",
    "client = OpenSearch(connection_string, use_ssl=True, timeout=100)\n",
    "client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "index_name = \"openai_wikipedia_index\"\n",
    "\n",
    "# Create the client with SSL/TLS enabled, but hostname verification disabled.\n",
    "client = OpenSearch(connection_string, use_ssl=True, timeout=100)\n",
    "\n",
    "res = client.search(index=index_name, body={\n",
    "    \"_source\": {},\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"text\": {\n",
    "                \"query\": \"Pizza\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "})\n",
    "\n",
    "print(\"\\n\".join([doc['_source']['title'] for doc in res[\"hits\"][\"hits\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run semantic search queries with LangChain and OpenSearch\n",
    "\n",
    "With the above embedding calculated, we can now run semantic searches against the OpenSearch index. We're using `knn` as query type and scan the content of the `content_vector` field.\n",
    "\n",
    "After running the block below, we should see content semantically similar to the question. Expect documents based on Pineapples, Pizza, Hawaii, Italy, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Define model\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "\n",
    "# Define the Client\n",
    "openaiclient = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "# Define question\n",
    "question = 'is ice cream a good option'\n",
    "\n",
    "# Create embedding\n",
    "question_embedding = openaiclient.embeddings.create(input=question + \"pizza toppings\", model=EMBEDDING_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opensearch_response = client.search(\n",
    "  index = index_name,\n",
    "  body = {\n",
    "      \"size\": 5,\n",
    "      \"query\" : {\n",
    "        \"knn\" : {\n",
    "          \"content_vector\":{\n",
    "            \"vector\":  question_embedding.data[0].embedding,\n",
    "            \"k\": 10\n",
    "          }\n",
    "       }\n",
    "     }\n",
    "  }\n",
    ")\n",
    "\n",
    "print(\"\\n\".join([doc['_source']['title'] for doc in opensearch_response['hits']['hits']]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "OpenSearch is a powerful tool providing both text and vector search capabilities. Used alongside LangChain allows you to craft personalized AI applications able to augment the context based on semantic search. LangChain's extensive modularity allows you to choose your\n",
    "\n",
    "You can try Aiven for OpenSearch, or any of the other Open Source tools, in the Aiven platform free trial by [signing up](https://go.aiven.io/openai-opensearch-signup)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
