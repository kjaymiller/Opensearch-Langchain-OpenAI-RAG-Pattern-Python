{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Using Langchain to create a custom prompt\n",
    "\n",
    "We've taken our data and used knn search to find articles close to our topic. Now we can use that information to help provide insight to our LLM and use that to help provide context to our chat bot.\n",
    "\n",
    "Let's run our search from the last notebook again. \n",
    "\n",
    "> **Reminder** For this data we used _OpenAI_ but our embeddings but this could we could have used any embedding algorithm. You can find other options on https://huggingface.co and similar websites.\n",
    "\n",
    "Let's once again preform a similarity search on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "from opensearchpy import OpenSearch\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "index_name = \"openai_wikipedia_index\"\n",
    "connection_string = os.getenv(\"OPENSEARCH_SERVICE_URI\")\n",
    "\n",
    "# Create the client with SSL/TLS enabled, but hostname verification disabled.\n",
    "opensearch_client = OpenSearch(connection_string, use_ssl=True, timeout=100)\n",
    "\n",
    "# Define model\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "\n",
    "# Define the Client\n",
    "openaiclient = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    )\n",
    "\n",
    "def search(\n",
    "        embedding:list[float],\n",
    "        index_name:str=index_name,\n",
    "        num_results:int=5,\n",
    "        k_distance:int=10\n",
    ") -> str:\n",
    "    \"\"\"Preform a search using the embedding and return the top 5 results.\"\"\"\n",
    "\n",
    "    return opensearch_client.search(\n",
    "        index = index_name,\n",
    "        body = {\n",
    "            \"size\": num_results,\n",
    "            \"query\" : {\n",
    "                \"knn\" : {\n",
    "                    \"content_vector\":{\n",
    "                        \"vector\": embedding,\n",
    "                        \"k\": k_distance,\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create embeddings for our question and preform a similarity search around pistacio being a good pizza topping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define questions\n",
    "question = \"Is pistachio ice cream good?\"\n",
    "\n",
    "question_embedding = openaiclient.embeddings.create(input=question + \"pizza toppings\", model=EMBEDDING_MODEL).data[0].embedding\n",
    "docs = search(question_embedding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll use the results from our search to augment our request. We'll also provide some guidance on how to present the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "# llm = ChatOllama()\n",
    "\n",
    "\n",
    "top_hit_summary = [doc['_source']['text'] for doc in opensearch_response[\"hits\"][\"hits\"]]\n",
    "\n",
    "template=\"\"\"\n",
    "You are an assistant for a school that trains Pizza restaurant franchise owners and chefs.\n",
    "\n",
    "Your goal is to helpo them find both traditional and unique ingredients for their pizza recipes.\n",
    "\n",
    "Your suggestions should be based on the following criteria:\n",
    " - Ingredients should be able to be added to the pizza as a topping or sauce\n",
    " - Ingredients should be able to be consumed by humans\n",
    " - Flavor profiles should be compatible with pizza\n",
    "\n",
    "Comment on their potential taste, texture, and how they might pair with other ingredients.\n",
    "\n",
    "Respond to this Question: {question}\n",
    "\n",
    "Don't suggest other ingredients.\n",
    "\n",
    "Use ONLY the data below to influence your answer\n",
    "{data}\n",
    "\n",
    "Keep your answer to limited to no more than 2 sentences.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template=template)\n",
    "\n",
    "chain = (\n",
    "    {\"question\": RunnablePassthrough(), \"data\": RunnablePassthrough()} | prompt | llm\n",
    ")\n",
    "\n",
    "response = chain.invoke({\"question\": question, \"data\": top_hit_summary})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "OpenSearch is a powerful tool providing both text and vector search capabilities. Used alongside LangChain allows you to craft personalized AI applications able to augment the context based on semantic search. LangChain's extensive modularity allows you to choose your\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
