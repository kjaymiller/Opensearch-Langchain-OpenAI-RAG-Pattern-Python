{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Load our environment variables and Connect to our Opensearch Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from opensearchpy import OpenSearch\n",
    "\n",
    "connection_string = os.getenv(\"OPENSEARCH_SERVICE_URI\")\n",
    "\n",
    "# Create the client with SSL/TLS enabled, but hostname verification disabled.\n",
    "client = OpenSearch(connection_string, use_ssl=True, timeout=100)\n",
    "client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "index_name = \"openai_wikipedia_index\"\n",
    "\n",
    "# Create the client with SSL/TLS enabled, but hostname verification disabled.\n",
    "client = OpenSearch(connection_string, use_ssl=True, timeout=100)\n",
    "\n",
    "res = client.search(index=index_name, body={\n",
    "    \"_source\": {},\n",
    "    \"query\": {\n",
    "        \"match\": {\n",
    "            \"text\": {\n",
    "                \"query\": \"Pizza\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "})\n",
    "\n",
    "pprint(res[\"hits\"][\"hits\"][0]['_source']['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run semantic search queries with LangChain and OpenSearch\n",
    "\n",
    "With the above embedding calculated, we can now run semantic searches against the OpenSearch index. We're using `knn` as query type and scan the content of the `content_vector` field.\n",
    "\n",
    "After running the block below, we should see content semantically similar to the question. Expect documents based on Pineapples, Pizza, Hawaii, Italy, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.vectorstores import OpenSearchVectorSearch\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "docsearch = OpenSearchVectorSearch(\n",
    "    index_name=index_name,\n",
    "    embedding_function=embeddings,\n",
    "    opensearch_url=connection_string,\n",
    ")\n",
    "\n",
    "# Define question\n",
    "question = 'is Spam and Salami a good ingredient for Pizza?'\n",
    "\n",
    "docs = docsearch.similarity_search(\n",
    "    question,\n",
    "    vector_field='content_vector',\n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "data = \"\"\n",
    "\n",
    "for doc in docs:\n",
    "  data += doc.page_content + \"\\n\\n\"\n",
    "\n",
    "pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "question = 'is Spam and Salami a good ingredient for Pizza?'\n",
    "\n",
    "prompt_no_data = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"\n",
    "Answer the following question: {question}\n",
    "Avoid mentioning terms in preference but focus your answer on if other successful restaurant as used the same ingredients in the question.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\", \"data\"],\n",
    "    template=\"\"\"\n",
    "Answer the following question: {question} using the data below:\n",
    "{data}\n",
    "\n",
    "Avoid mentioning terms in preference but focus your answer on if other successful restaurant including their name if possible as used the same ingredients in the question.\n",
    "\"\"\")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_no_data)\n",
    "# pprint(chain.run({\"question\": question}))\n",
    "pprint(chain.run({\"question\": question, \"data\":data}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "OpenSearch is a powerful tool providing both text and vector search capabilities. Used alongside LangChain allows you to craft personalized AI applications able to augment the context based on semantic search. LangChain's extensive modularity allows you to choose your\n",
    "\n",
    "You can try Aiven for OpenSearch, or any of the other Open Source tools, in the Aiven platform free trial by [signing up](https://go.aiven.io/openai-opensearch-signup)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
